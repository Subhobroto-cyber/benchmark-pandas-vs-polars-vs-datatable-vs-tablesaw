This project benchmarks the performance of DataFrame libraries—starting with pandas—on a large 1GB CSV dataset (~30 million rows). It measures execution time and memory usage across key operations like reading, writing, grouping, sorting, and converting to NumPy arrays. The goal is to evaluate the scalability and efficiency of different libraries when handling real-world, high-volume data workloads. Future extensions include benchmarking polars(in Rust as well), datatable, and Tablesaw for comparative analysis.
